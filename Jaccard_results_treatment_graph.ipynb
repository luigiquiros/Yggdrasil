{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import os\n",
    "from io import StringIO  # Import StringIO from the io module\n",
    "import time  # Import the time module\n",
    "from urllib.parse import quote  # To URL encode SMILES\n",
    "import plotly.express as px\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befor runing this code: \n",
    "1) create a .csv file containing a 'species_header' like 'species', 'names', etc. this column should contain the name of the species (or genuses by default) resolved by Open Tree of Life.\n",
    "2) creta an empty folder (input_folder) and put the .csv file inside! \n",
    "\n",
    "That's all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE FOLLOWING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "# Input folder containing CSV files\n",
    "input_folder = '/mnt/c/Users/quirosgu/Desktop/OK/' #/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/V1V2/'\n",
    "\n",
    "species_header = 'full_species'#'query_otol_species' #put the column of your species\n",
    "\n",
    "LOTUSDB = '/mnt/c/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv' #'/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv'\n",
    "LOTUSDB_rc = '/mnt/c/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv' #'/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv'\n",
    "\n",
    "# Output folder for the processed CSV files\n",
    "output_folder = f'{input_folder}output_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file_name in csv_files:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract 'MassIVE' code from 'feature' column\n",
    "    df['MassIVE'] = df['feature'].str.extract(r'mzspec:(MSV\\d+):')\n",
    "\n",
    "    # Extract 'ms_filename' from 'feature' column\n",
    "    ms_filename_match = df['feature'].str.extract(r'[^:]+:[^:]+:([^:]+)_features_ms2_(pos|neg).mgf:')\n",
    "    if ms_filename_match is not None and len(ms_filename_match.columns) == 2:\n",
    "        df['ms_filename'] = ms_filename_match[0]\n",
    "    \n",
    "    # Extract 'scan' from 'feature' column\n",
    "    df['scan'] = df['feature'].str.extract(r'scan:(\\d+)')\n",
    "    \n",
    "    # Perform any additional modifications to the DataFrame here\n",
    "    \n",
    "    # Save the modified DataFrame back to the same file\n",
    "    df.to_csv(file_path, index=False)  # Set index=False to exclude the index column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file_name in csv_files:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Filter rows where 'jaccard_similarity' > 0.1\n",
    "    filtered_df = df[df['jaccard_similarity'] > 0.25]\n",
    "    \n",
    "    # Extract unique 'feature_query' and 'ms_filename' pairs\n",
    "    unique_pairs = filtered_df[['feature_query', 'ms_filename']].drop_duplicates()\n",
    "    \n",
    "    # Append the unique pairs to the list of DataFrames\n",
    "    dfs.append(unique_pairs)\n",
    "\n",
    "# Concatenate all DataFrames into a single combined DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(f'{input_folder} combined_results_js25.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c38b6a57c2d4f85bcd8a646c69c70f453ebfd581092159d4a2b022d1b3585cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
