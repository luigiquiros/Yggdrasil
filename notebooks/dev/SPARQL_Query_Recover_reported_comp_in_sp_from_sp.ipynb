{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import os\n",
    "from io import StringIO  # Import StringIO from the io module\n",
    "import time  # Import the time module\n",
    "from urllib.parse import quote  # To URL encode SMILES\n",
    "import plotly.express as px\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befor runing this code: \n",
    "1) creaea an empty folder (input_folder) in your desired location and writhe down the path below! \n",
    "2) Change the corresponding Q CODE from wikidata for a given Genus in the code below!\n",
    "\n",
    "That's all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE FOLLOWING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "# Input folder containing CSV files\n",
    "input_folder = 'C:/Users/quirosgu/Desktop/Maytenus/Literature/'\n",
    "#\"//FARMA-AD2.farma.unige.ch/Pharmacie/Recherche/COMMON FASIE-FATHO/Luis/Side Projects/article Lisa/\"\n",
    "\n",
    "#Swertia chirayita (Q21318003)\n",
    "#Swertia (Q163970)\n",
    "#Gentianaceae (Q157216)\n",
    "species_name = 'Maytenus blepharodes' #'your_species_name_here'  # Replace 'your_species_name_here' with the actual species name\n",
    "qcode = \"Q15329945\"  # Replace with the actual Q-code for the genus\n",
    "\n",
    "#lotus databases\n",
    "LOTUSDB = 'C:/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv'#'/mnt/c/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv' #'/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv' #'/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv' #'C:/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv'#'/mnt/c/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv' #'/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/Yggdrasil/data_loc/LotusDB_inhouse_metadata.csv'\n",
    "LOTUSDB_rc = 'C:/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv'#'/mnt/c/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv' #'C:/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv'#'/mnt/c/Users/quirosgu/Documents/Github/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv' #'/home/quirosgu/Desktop/FARMA-SHARE/RECHERCHE/FASIE_LAB/LuisQ/Yggdrasil/data_loc/LotusDB_inhouse_rc.csv'\n",
    "\n",
    "# Output folder for the processed CSV files\n",
    "output_folder = f'{input_folder}output_data/'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#functions to colors palets, etc\n",
    "def fetch_species_from_qcode(qcode):\n",
    "    \"\"\"\n",
    "    Fetches all species under a given genus using the Wikidata SPARQL endpoint.\n",
    "\n",
    "    Parameters:\n",
    "    genus_qcode (str): The Wikidata Q-code for the genus.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the species and their corresponding Q-codes.\n",
    "    \"\"\"\n",
    "\n",
    "    # SPARQL query to fetch species under a given genus\n",
    "    query = \"\"\"\n",
    "    SELECT ?species ?speciesLabel WHERE {\n",
    "      ?species wdt:P171* wd:%s .\n",
    "      ?species wdt:P105 wd:Q7432.\n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "    }\n",
    "    \"\"\" % qcode\n",
    "\n",
    "    # URL for the Wikidata SPARQL endpoint\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    # Request headers\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Wikidata Species Fetcher/0.1 (https://www.wikidata.org/wiki/Wikidata:Data_access)\"\n",
    "    }\n",
    "\n",
    "    # Perform the request\n",
    "    response = requests.get(url, headers=headers, params={'query': query, 'format': 'json'})\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Failed to fetch data: HTTP status code {}\".format(response.status_code))\n",
    "\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract results\n",
    "    species = []\n",
    "    for item in data['results']['bindings']:\n",
    "        species.append({\n",
    "            'wikidata_Qcode_species': item['species']['value'].split('/')[-1],\n",
    "            'Species': item['speciesLabel']['value']\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(species)\n",
    "\n",
    "# Define base colors for each Pathway\n",
    "pathway_shades= {\n",
    "    'Terpenoids': ('#618264', '#D0E7D2'),  # Green start and lighter green end\n",
    "    'Alkaloids': ('#305F72', '#5CBCE2'),   # Blue start and lighter blue end  \n",
    "    'Shikimates and Phenylpropanoids': ('#80558C', '#CBA0AE'),  # Purple start and lighter purple end\n",
    "    'Polyketides': ('#EF4B4B', '#EC8F6A'),  # Red start and lighter purple end\n",
    "    'Fatty acids': ('#FF6C22', '#FF9209'),  # Orange start and lighter purple end\n",
    "    'Amino acids and Peptides': ('#F4E869', '#FAF2D3'),  # Yellow start and lighter purple end\n",
    "    'Carbohydrates': ('#65451F','#C8AE7D')  # Brown start and lighter purple end\n",
    "}\n",
    "\n",
    "# Define custom colors for the 7 pathway categories\n",
    "pathway_colors = {\n",
    "    'Terpenoids': '#618264',  # Green start and lighter green end\n",
    "    'Alkaloids': '#305F72',   # Blue start and lighter blue end\n",
    "    'Shikimates and Phenylpropanoids': '#80558C',  # Purple start and lighter purple end\n",
    "    'Polyketides': '#EF4B4B',  # Red start and lighter purple end\n",
    "    'Fatty acids': '#FF6C22',  # Orange start and lighter purple end\n",
    "    'Amino acids and Peptides': '#F4E869',  # Yellow start and lighter purple end\n",
    "    'Carbohydrates': '#65451F' # Brown start and lighter purple end\n",
    "}\n",
    "\n",
    "def interpolate_color(color1, color2, factor: float):\n",
    "    \"\"\"Interpolate between two colors\"\"\"\n",
    "    color1 = np.array(mcolors.to_rgb(color1))\n",
    "    color2 = np.array(mcolors.to_rgb(color2))\n",
    "    return mcolors.to_hex((1 - factor) * color1 + factor * color2)\n",
    "\n",
    "def generate_shades(pathway, num_shades):\n",
    "    base_color, end_color = pathway_shades.get(pathway, ('gray', 'lightgray'))\n",
    "    if num_shades == 1:\n",
    "        return [base_color]  # Return the base color if only one shade is requested\n",
    "    shades = []\n",
    "    for i in range(num_shades):\n",
    "        factor = i / (num_shades - 1)\n",
    "        shades.append(interpolate_color(base_color, end_color, factor))\n",
    "    return shades\n",
    "\n",
    "def split_chemical_superclass(row):\n",
    "    # Check if the value is a string before splitting\n",
    "    if isinstance(row['chemical_superclass'], str):\n",
    "        parts = row['chemical_superclass'].split('-')\n",
    "        if len(parts) == 2:\n",
    "            return parts[0], parts[1]  # Pathway and Superclass are present\n",
    "        else:\n",
    "            return parts[0], 'Unknown'  # Only Pathway is present, or the format is not as expected\n",
    "    else:\n",
    "        # Return default values if the entry is NaN or not a string\n",
    "        return 'Unknown', 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIRST RECOVER THE SPECIES (and Q codes) BELONGING TO A PARTICULAR GENUS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "species_df = fetch_species_from_qcode(qcode)\n",
    "species_df.head()  # Display the first few rows\n",
    "\n",
    "# Filename for the CSV file\n",
    "file_name = \"species_list.csv\"\n",
    "\n",
    "# Full path for the CSV file\n",
    "full_file_path = f\"{input_folder}/{file_name}\"\n",
    "\n",
    "# Save the DataFrame to a CSV file in the specified folder\n",
    "species_df.to_csv(full_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW, LETS USE THE QCODES TO RECOVER ALL THE COMPOUNDS (WITH REFERENCES) PRESENT IN EACH QCODE AND SAVE THEM AS INDIVIDUAL CSV FILES FROM LOTUS_DB FROZEN METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grouped data for Q code Q15329945 to C:/Users/quirosgu/Desktop/Maytenus/Literature/output_data/species_data\\Q15329945.tsv\n"
     ]
    }
   ],
   "source": [
    "# Load the LOTUSDB CSV\n",
    "lotusdb_df = pd.read_csv(LOTUSDB, low_memory=False)\n",
    "\n",
    "# Iterate through all CSV files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Load the CSV file with Q codes\n",
    "        df_species = pd.read_csv(input_file)\n",
    "\n",
    "        # Iterate through the Q codes in the species CSV\n",
    "        for q_code in df_species['wikidata_Qcode_species']:  # Ensure this column name matches your species CSV\n",
    "            # Skip processing if Q code is 'Not Found'\n",
    "            if q_code == 'Not Found':\n",
    "                continue\n",
    "\n",
    "            # Filter LOTUSDB data for the current Q code\n",
    "            filtered_lotusdb = lotusdb_df[lotusdb_df['wikidata_Qcode'] == q_code]  # Ensure this column name matches your LOTUSDB CSV\n",
    "\n",
    "            # Group and aggregate the data\n",
    "            grouped_df = filtered_lotusdb.groupby(\"structure_inchikey\").agg({\n",
    "                # Add all the aggregation rules here\n",
    "                # Example:\n",
    "                \"structure_wikidata\": \"first\",\n",
    "                \"structure_inchi\": \"first\",\n",
    "                \"structure_smiles\": \"first\",\n",
    "                \"structure_molecular_formula\": \"first\",\n",
    "                \"structure_exact_mass\": \"first\",\n",
    "                \"structure_xlogp\": \"first\",\n",
    "                \"structure_smiles_2D\": \"first\",\n",
    "                \"structure_cid\": \"first\",\n",
    "                \"structure_nameIupac\": \"first\",\n",
    "                \"structure_nameTraditional\": \"first\",\n",
    "                \"structure_taxonomy_npclassifier_01pathway\": \"first\",\n",
    "                \"structure_taxonomy_npclassifier_02superclass\": \"first\",\n",
    "                \"structure_taxonomy_npclassifier_03class\": \"first\",\n",
    "                \"organism_wikidata\": \"first\",\n",
    "                \"organism_taxonomy_gbifid\": \"first\",\n",
    "                \"organism_taxonomy_ncbiid\": \"first\",\n",
    "                \"organism_taxonomy_ottid\": \"first\",\n",
    "                \"organism_taxonomy_01domain\": \"first\",\n",
    "                \"organism_taxonomy_02kingdom\": \"first\",\n",
    "                \"organism_taxonomy_03phylum\": \"first\",\n",
    "                \"organism_taxonomy_04class\": \"first\",\n",
    "                \"organism_taxonomy_05order\": \"first\",\n",
    "                \"organism_taxonomy_06family\": \"first\",\n",
    "                \"organism_taxonomy_07tribe\": \"first\",\n",
    "                \"organism_taxonomy_08genus\": \"first\",\n",
    "                \"organism_taxonomy_09species\": \"first\",\n",
    "                \"organism_taxonomy_10varietas\": \"first\",\n",
    "                \"reference_wikidata\": lambda x: \"|\".join(map(str, x)),\n",
    "                \"reference_doi\": lambda x: \"|\".join(map(str, x))\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Create 'chemical_superclass' and 'chemical_class' columns\n",
    "            grouped_df['chemical_superclass'] = grouped_df['structure_taxonomy_npclassifier_01pathway'] + '-' + grouped_df['structure_taxonomy_npclassifier_02superclass']\n",
    "            grouped_df['chemical_class'] = grouped_df['structure_taxonomy_npclassifier_01pathway'] + '-' + grouped_df['structure_taxonomy_npclassifier_03class']\n",
    "            \n",
    "            # Save the grouped data as a TSV file with the Q code as the filename\n",
    "            output_subfolder = os.path.join(output_folder, 'species_data')\n",
    "            #if not os.path.exists(output_subfolder):\n",
    "            os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "            output_filename = os.path.join(output_subfolder, f\"{q_code}.tsv\")\n",
    "            grouped_df.to_csv(output_filename, index=False, sep='\\t')\n",
    "\n",
    "            print(f\"Saved grouped data for Q code {q_code} to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECOVER THE FRECUENCE BY CHEMICAL CLASS AND ADDED TO THE GENERAL TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['wikidata_Qcode'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#add reported compounds to each Q code\u001b[39;00m\n\u001b[0;32m     62\u001b[0m LotusDB_rc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(LOTUSDB_rc)\n\u001b[1;32m---> 64\u001b[0m spDB \u001b[38;5;241m=\u001b[39m \u001b[43mLotusDB_rc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwikidata_Qcode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReported_comp_Species\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m     65\u001b[0m gDB \u001b[38;5;241m=\u001b[39m LotusDB_rc[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morganism_taxonomy_08genus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReported_comp_Genus\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m     66\u001b[0m fDB \u001b[38;5;241m=\u001b[39m LotusDB_rc[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morganism_taxonomy_06family\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReported_comp_Family\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['wikidata_Qcode'] not in index\""
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize variables to store data\n",
    "total_compounds = {}\n",
    "chemical_classes = {}\n",
    "chemical_superclasses = {}\n",
    "references = {}\n",
    "hyperlinks = {}\n",
    "\n",
    "# Step 2: Iterate through .tsv files in the folder\n",
    "\n",
    "species_data_folder = os.path.join(output_folder, 'species_data')\n",
    "for filename in os.listdir(species_data_folder):\n",
    "    if filename.endswith(\".tsv\"):\n",
    "        qcode = filename.split(\".\")[0]  # Extract Qcode from the filename\n",
    "\n",
    "        # Load the .tsv file into a DataFrame\n",
    "        df_compounds = pd.read_csv(os.path.join(species_data_folder, filename), sep='\\t')\n",
    "\n",
    "        # Step 3: Calculate frequencies of chemical classes for each Qcode (excluding 'not classified')\n",
    "        filtered_classes = df_compounds[df_compounds['structure_taxonomy_npclassifier_03class'] != 'Not Classified']\n",
    "        grouped = filtered_classes['structure_taxonomy_npclassifier_03class'].value_counts().reset_index()\n",
    "        frequencies = grouped.apply(lambda row: f\"{row.name} {row['structure_taxonomy_npclassifier_03class']}\", axis=1)\n",
    "        chemical_classes[qcode] = \"|\".join(frequencies)\n",
    "\n",
    "        # Step 4: Calculate frequencies of chemical superclasses for each Qcode (excluding 'not classified')\n",
    "        filtered_sclasses = df_compounds[df_compounds['structure_taxonomy_npclassifier_02superclass'] != 'Not Classified']\n",
    "        sgrouped = filtered_sclasses['structure_taxonomy_npclassifier_02superclass'].value_counts().reset_index()\n",
    "        frequencies = sgrouped.apply(lambda row: f\"{row.name} {row['structure_taxonomy_npclassifier_02superclass']}\", axis=1)\n",
    "        chemical_superclasses[qcode] = \"|\".join(frequencies)\n",
    "        chemical_classes[qcode] = \"|\".join(frequencies)\n",
    "        \n",
    "        # Step 5: Combine references and hyperlinks\n",
    "        #references[qcode] = \"|\".join(df_compounds['reference_wikidata'].dropna())\n",
    "        #hyperlinks[qcode] = \"|\".join(df_compounds['reference_doi'].dropna())\n",
    "\n",
    "        # Step 6: Calculate the total number of reported compounds\n",
    "        #total_compounds[qcode] = len(df_compounds)\n",
    "\n",
    "# Step 7: Load the general info .csv into a DataFrame\n",
    "csv_file = None\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_file = os.path.join(input_folder, filename)\n",
    "        break  # Stop searching after finding the first CSV file\n",
    "\n",
    "if csv_file is not None:\n",
    "    # Load the CSV file into the df_general_info DataFrame\n",
    "    df_general_info = pd.read_csv(csv_file)\n",
    "\n",
    "# Step 7: Create new columns for combined information\n",
    "df_general_info['predicted_class'] = df_general_info['wikidata_Qcode_species'].map(chemical_classes)\n",
    "df_general_info['predicted_superclass'] = df_general_info['wikidata_Qcode_species'].map(chemical_superclasses)\n",
    "#df_general_info['references'] = df_general_info['wikidata_Qcode_species'].map(references)\n",
    "#df_general_info['referenceLabel'] = df_general_info['wikidata_Qcode_species'].map(hyperlinks)\n",
    "\n",
    "# Step 7: Save the updated DataFrame to the .csv file\n",
    "\n",
    "# Replace values matching the pattern with an empty cell\n",
    "df_general_info['predicted_class'] = df_general_info['predicted_class'].replace('index|predicted_class', '')\n",
    "df_general_info['predicted_superclass'] = df_general_info['predicted_superclass'].replace('index|predicted_superclass', '')\n",
    "\n",
    "#add reported compounds to each Q code\n",
    "LotusDB_rc = pd.read_csv(LOTUSDB_rc)\n",
    "\n",
    "spDB = LotusDB_rc[['wikidata_Qcode', 'Reported_comp_Species']].drop_duplicates()\n",
    "gDB = LotusDB_rc[['organism_taxonomy_08genus', 'Reported_comp_Genus']].drop_duplicates()\n",
    "fDB = LotusDB_rc[['organism_taxonomy_06family', 'Reported_comp_Family']].drop_duplicates()\n",
    "\n",
    "df = pd.merge(df_general_info, spDB,\n",
    "            how= 'left', left_on='wikidata_Qcode_species', right_on='wikidata_Qcode')#.drop_duplicates(subset=['CODE'])\n",
    "df.drop('wikidata_Qcode', axis=1, inplace=True)\n",
    "\n",
    "#df = pd.merge(df, gDB,\n",
    "#            how= 'left', left_on='genus', right_on='organism_taxonomy_08genus')#.drop_duplicates(subset=['full_species'])\n",
    "#df.drop('organism_taxonomy_08genus', axis=1, inplace=True)\n",
    "\n",
    "#df = pd.merge(df, fDB,\n",
    "#            how= 'left', left_on='family', right_on='organism_taxonomy_06family')#.drop_duplicates(subset=['full_species'])\n",
    "#df.drop('organism_taxonomy_06family', axis=1, inplace=True)\n",
    "\n",
    "output_csv_file = output_folder + 'Full_results.csv'\n",
    "df.to_csv(output_csv_file, index=False, sep =',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARPLOT CHEMICAL CLASS - SPECIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m all_data \u001b[38;5;241m=\u001b[39m all_data[\u001b[38;5;241m~\u001b[39mall_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchemical_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI Error-API Error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Classified-Not Classified\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Apply the function to each row\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPathway\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchemical_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: split_chemical_superclass(row), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 4: Process data for color mapping\u001b[39;00m\n\u001b[0;32m     17\u001b[0m color_map \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\frame.py:4341\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4337\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[0;32m   4338\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[0;32m   4340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 4341\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m   4343\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:390\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read data from all .tsv files in the output_folder\n",
    "all_data = pd.concat([pd.read_csv(os.path.join(output_folder, 'species_data', filename), sep='\\t') for filename in os.listdir(os.path.join(output_folder, 'species_data')) if filename.endswith(\".tsv\")])\n",
    "\n",
    "# Step 2: Rename the \"organism_taxonomy_09species\" column to \"species\"\n",
    "all_data.rename(columns={'organism_taxonomy_09species': 'species'}, inplace=True)\n",
    "\n",
    "# Remove 'API Error-API Error' and 'Not Classified-Not Classified'\n",
    "all_data = all_data[~all_data['chemical_class'].isin(['API Error-API Error', 'Not Classified-Not Classified'])]\n",
    "\n",
    "# Apply the function to each row\n",
    "all_data[['Pathway', 'chemical_class']] = all_data.apply(lambda row: split_chemical_superclass(row), axis=1, result_type='expand')\n",
    "\n",
    "# Step 4: Process data for color mapping\n",
    "color_map = {}\n",
    "for pathway, superclasses in all_data.groupby('Pathway')['chemical_class'].unique().items():\n",
    "    shades = generate_shades(pathway, len(superclasses))\n",
    "    for superclass, shade in zip(superclasses, shades):\n",
    "        color_map[f\"{pathway}-{superclass}\"] = shade\n",
    "\n",
    "# Step 5: Group and aggregate data to calculate recurrence for a specific species\n",
    "\n",
    "agg_data = all_data[all_data['species'] == species_name].groupby('chemical_class').size().reset_index(name='recurrence')\n",
    "\n",
    "# Get unique chemical superclasses and sort them alphabetically\n",
    "unique_superclasses = sorted(agg_data['chemical_class'].unique())\n",
    "\n",
    "# Create the bar plot\n",
    "fig = px.bar(agg_data, x='chemical_class', y='recurrence',\n",
    "             title=f'Barplot of Predicted Superclasses Occurrence for {species_name}',\n",
    "             labels={'recurrence': 'Recurrence'},\n",
    "             color='chemical_class',\n",
    "             color_discrete_map=color_map,\n",
    "             category_orders={'chemical_class': unique_superclasses},\n",
    "             orientation='v')  # Vertical bar plot\n",
    "\n",
    "# Set a white background\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "\n",
    "# Modify the size of the figure\n",
    "fig.update_layout(width=1200, height=800)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(f'{output_folder}Wikidata_class_barplot_{species_name}.html')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "# Create the sunburst plot\n",
    "fig = px.sunburst(agg_data, path=['chemical_class'], values='recurrence',\n",
    "                  title=f'Sunburst Plot of Chemical Superclasses Occurrence for {species_name}',\n",
    "                  color='chemical_class',\n",
    "                  color_discrete_map=color_map)\n",
    "\n",
    "# Modify the size of the figure\n",
    "fig.update_layout(width=800, height=800)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(f'{output_folder}Wikidata_class_sunburst_{species_name}.html')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARPLOT CHEMICAL_SUPERCLASS - SPECIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m all_data \u001b[38;5;241m=\u001b[39m all_data[\u001b[38;5;241m~\u001b[39mall_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchemical_superclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI Error-API Error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Classified-Not Classified\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Apply the function to each row\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPathway\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: split_chemical_superclass(row), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 4: Process data for color mapping\u001b[39;00m\n\u001b[0;32m     17\u001b[0m color_map \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\frame.py:4341\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4337\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[0;32m   4338\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[0;32m   4340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 4341\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m   4343\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[1;32mc:\\Users\\quirosgu\\.conda\\envs\\inventa\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:390\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read data from all .tsv files in the output_folder\n",
    "all_data = pd.concat([pd.read_csv(os.path.join(output_folder, 'species_data', filename), sep='\\t') for filename in os.listdir(os.path.join(output_folder, 'species_data')) if filename.endswith(\".tsv\")])\n",
    "\n",
    "# Step 2: Rename the \"organism_taxonomy_09species\" column to \"species\"\n",
    "all_data.rename(columns={'organism_taxonomy_09species': 'species'}, inplace=True)\n",
    "\n",
    "# Remove 'API Error-API Error' and 'Not Classified-Not Classified'\n",
    "all_data = all_data[~all_data['chemical_superclass'].isin(['API Error-API Error', 'Not Classified-Not Classified'])]\n",
    "\n",
    "# Apply the function to each row\n",
    "all_data[['Pathway', 'superclass']] = all_data.apply(lambda row: split_chemical_superclass(row), axis=1, result_type='expand')\n",
    "\n",
    "# Step 4: Process data for color mapping\n",
    "color_map = {}\n",
    "for pathway, superclasses in all_data.groupby('Pathway')['superclass'].unique().items():\n",
    "    shades = generate_shades(pathway, len(superclasses))\n",
    "    for superclass, shade in zip(superclasses, shades):\n",
    "        color_map[f\"{pathway}-{superclass}\"] = shade\n",
    "\n",
    "# Step 5: Group and aggregate data to calculate recurrence for a specific species\n",
    "\n",
    "agg_data = all_data[all_data['species'] == species_name].groupby('chemical_superclass').size().reset_index(name='recurrence')\n",
    "\n",
    "# Get unique chemical superclasses and sort them alphabetically\n",
    "unique_superclasses = sorted(agg_data['chemical_superclass'].unique())\n",
    "\n",
    "# Create the bar plot\n",
    "fig = px.bar(agg_data, x='chemical_superclass', y='recurrence',\n",
    "             title=f'Barplot of Predicted Superclasses Occurrence for {species_name}',\n",
    "             labels={'recurrence': 'Recurrence'},\n",
    "             color='chemical_superclass',\n",
    "             color_discrete_map=color_map,\n",
    "             category_orders={'chemical_superclass': unique_superclasses},\n",
    "             orientation='v')  # Vertical bar plot\n",
    "\n",
    "# Set a white background\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "\n",
    "# Modify the size of the figure\n",
    "fig.update_layout(width=1200, height=800)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(f'{output_folder}Wikidata_superclass_barplot_{species_name}.html')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "# Create the sunburst plot\n",
    "fig = px.sunburst(agg_data, path=['chemical_superclass'], values='recurrence',\n",
    "                  title=f'Sunburst Plot of Chemical Superclasses Occurrence for {species_name}',\n",
    "                  color='chemical_superclass',\n",
    "                  color_discrete_map=color_map)\n",
    "\n",
    "# Modify the size of the figure\n",
    "fig.update_layout(width=800, height=800)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(f'{output_folder}Wikidata_superclass_sunburst_{species_name}.html')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c38b6a57c2d4f85bcd8a646c69c70f453ebfd581092159d4a2b022d1b3585cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
